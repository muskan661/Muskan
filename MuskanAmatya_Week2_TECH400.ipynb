{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import the Library"
      ],
      "metadata": {
        "id": "99d6Kh3tbDFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3peyY2yLUfhN",
        "outputId": "a588febc-0b34-483b-9c8c-3b177eb94b82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Import the library\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Ensure the required NLTK packages are downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the text documents"
      ],
      "metadata": {
        "id": "5G3WUfzLbG7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the text documents\n",
        "def load_documents():\n",
        "    documents = {\n",
        "        1: \"What problems and concerns are there in making up descriptive titles?\",\n",
        "        2: \"How can actually pertinent data, as opposed to references or entire articles themselves, be retrieved automatically in response to information requests?\",\n",
        "        3: \"What is information science? Give definitions where possible.\",\n",
        "        4: \"Image recognition and any other methods of automatically transforming printed text into computer-ready form.\",\n",
        "        5: \"What special training will ordinary researchers and businessmen need for proper information management and unobstructed use of information retrieval systems?\"\n",
        "    }\n",
        "    return documents"
      ],
      "metadata": {
        "id": "dmKjrLYMUyCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text cleaning pipeline"
      ],
      "metadata": {
        "id": "ad2v9aAQbJuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text cleaning Pipeline\n",
        "def clean_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Tokenize\n",
        "    words = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return words"
      ],
      "metadata": {
        "id": "jmZUbldzU33_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inverted Index"
      ],
      "metadata": {
        "id": "D7J1nUwkbQWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Inverted Index Creation\n",
        "def create_indexes(documents):\n",
        "    inverted_index = defaultdict(list)\n",
        "    reverse_dictionary = defaultdict(list)\n",
        "\n",
        "    for doc_id, content in documents.items():\n",
        "        words = clean_text(content)\n",
        "\n",
        "        # Build inverted index (word -> list of doc_ids)\n",
        "        for word in words:\n",
        "            if doc_id not in inverted_index[word]:\n",
        "                inverted_index[word].append(doc_id)\n",
        "\n",
        "        # Build reverse dictionary (doc_id -> list of words)\n",
        "        reverse_dictionary[doc_id] = words\n",
        "\n",
        "    return inverted_index, reverse_dictionary"
      ],
      "metadata": {
        "id": "M09n3f31VEHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boolean Query"
      ],
      "metadata": {
        "id": "AH93KKRHbUQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Boolean Query Implementation (AND logic)\n",
        "def boolean_query(query, inverted_index, operator=\"AND\"):\n",
        "    query_words = clean_text(query)\n",
        "\n",
        "    # If no query words are present after cleaning, return an empty set\n",
        "    if not query_words:\n",
        "        return set()\n",
        "\n",
        "    # AND Logic: Intersect all the sets of documents\n",
        "    if operator == \"AND\":\n",
        "        result = set(inverted_index[query_words[0]])\n",
        "        for word in query_words[1:]:\n",
        "            result = result.intersection(set(inverted_index[word]))\n",
        "        return result\n",
        "\n",
        "    # OR Logic: Union all the sets of documents\n",
        "    elif operator == \"OR\":\n",
        "        result = set()\n",
        "        for word in query_words:\n",
        "            result = result.union(set(inverted_index[word]))\n",
        "        return result\n",
        "\n",
        "    # NOT Logic: Exclude documents containing certain words\n",
        "    elif operator == \"NOT\":\n",
        "        # Get all document IDs\n",
        "        all_docs = set(inverted_index.keys())\n",
        "        # Start with all documents and remove those that contain the query words\n",
        "        result = all_docs.copy()\n",
        "        for word in query_words:\n",
        "            result = result.difference(set(inverted_index[word]))\n",
        "        return result\n",
        "\n",
        "    # If no valid operator is provided, return an empty set\n",
        "    else:\n",
        "        return set()"
      ],
      "metadata": {
        "id": "0wqqD8tIVIyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main function"
      ],
      "metadata": {
        "id": "9YU2GymkbaSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load the documents\n",
        "    documents = load_documents()\n",
        "\n",
        "    # Create both the inverted index and reverse dictionary\n",
        "    inverted_index, reverse_dictionary = create_indexes(documents)\n",
        "\n",
        "    # Display the inverted index\n",
        "    print(\"Inverted Index:\")\n",
        "    for word, doc_ids in inverted_index.items():\n",
        "        print(f\"{word}: {doc_ids}\")\n",
        "\n",
        "    # Display the reverse dictionary\n",
        "    print(\"\\nReverse Dictionary:\")\n",
        "    for doc_id, words in reverse_dictionary.items():\n",
        "        print(f\"Document {doc_id}: {words}\")\n",
        "\n",
        "    # Perform Boolean queries with AND, OR, and NOT logic\n",
        "\n",
        "    # AND query example: Find documents containing both 'problems' and 'concerns'\n",
        "    query = \"problems concerns\"\n",
        "    result = boolean_query(query, inverted_index, operator=\"AND\")\n",
        "    print(f\"\\nDocuments matching AND query '{query}': {result}\")\n",
        "\n",
        "    # OR query example: Find documents containing either 'data' or 'retrieved'\n",
        "    query_or = \"data retrieved\"\n",
        "    result_or = boolean_query(query_or, inverted_index, operator=\"OR\")\n",
        "    print(f\"\\nDocuments matching OR query '{query_or}': {result_or}\")\n",
        "\n",
        "    # NOT query example: Find documents NOT containing 'science'\n",
        "    query_not = \"science\"\n",
        "    result_not = boolean_query(query_not, inverted_index, operator=\"NOT\")\n",
        "    print(f\"\\nDocuments matching NOT query '{query_not}': {result_not}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SWUNUHWVMpQ",
        "outputId": "398f4d19-649a-4d14-e637-5e8c33f87a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inverted Index:\n",
            "problems: [1]\n",
            "concerns: [1]\n",
            "making: [1]\n",
            "descriptive: [1]\n",
            "titles: [1]\n",
            "actually: [2]\n",
            "pertinent: [2]\n",
            "data: [2]\n",
            "opposed: [2]\n",
            "references: [2]\n",
            "entire: [2]\n",
            "articles: [2]\n",
            "retrieved: [2]\n",
            "automatically: [2, 4]\n",
            "response: [2]\n",
            "information: [2, 3, 5]\n",
            "requests: [2]\n",
            "science: [3]\n",
            "give: [3]\n",
            "definitions: [3]\n",
            "possible: [3]\n",
            "image: [4]\n",
            "recognition: [4]\n",
            "methods: [4]\n",
            "transforming: [4]\n",
            "printed: [4]\n",
            "text: [4]\n",
            "computerready: [4]\n",
            "form: [4]\n",
            "special: [5]\n",
            "training: [5]\n",
            "ordinary: [5]\n",
            "researchers: [5]\n",
            "businessmen: [5]\n",
            "need: [5]\n",
            "proper: [5]\n",
            "management: [5]\n",
            "unobstructed: [5]\n",
            "use: [5]\n",
            "retrieval: [5]\n",
            "systems: [5]\n",
            "\n",
            "Reverse Dictionary:\n",
            "Document 1: ['problems', 'concerns', 'making', 'descriptive', 'titles']\n",
            "Document 2: ['actually', 'pertinent', 'data', 'opposed', 'references', 'entire', 'articles', 'retrieved', 'automatically', 'response', 'information', 'requests']\n",
            "Document 3: ['information', 'science', 'give', 'definitions', 'possible']\n",
            "Document 4: ['image', 'recognition', 'methods', 'automatically', 'transforming', 'printed', 'text', 'computerready', 'form']\n",
            "Document 5: ['special', 'training', 'ordinary', 'researchers', 'businessmen', 'need', 'proper', 'information', 'management', 'unobstructed', 'use', 'information', 'retrieval', 'systems']\n",
            "\n",
            "Documents matching AND query 'problems concerns': {1}\n",
            "\n",
            "Documents matching OR query 'data retrieved': {2}\n",
            "\n",
            "Documents matching NOT query 'science': {'problems', 'opposed', 'businessmen', 'methods', 'science', 'computerready', 'retrieval', 'response', 'information', 'text', 'transforming', 'articles', 'requests', 'concerns', 'printed', 'possible', 'give', 'automatically', 'pertinent', 'systems', 'ordinary', 'definitions', 'descriptive', 'recognition', 'management', 'use', 'titles', 'form', 'need', 'making', 'retrieved', 'proper', 'references', 'data', 'image', 'special', 'researchers', 'actually', 'training', 'unobstructed', 'entire'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kiiS9pqWumb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}